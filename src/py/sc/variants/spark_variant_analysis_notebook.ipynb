{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Spark 4.0 Variant Data Type Analysis - Complete Use Cases\n",
        "\n",
        "## Overview\n",
        "This notebook demonstrates the power of Apache Spark 4.0's new **Variant data type** for processing heterogeneous, semi-structured data across three real-world use cases:\n",
        "\n",
        "### üéØ **Use Cases Covered**\n",
        "1. **üõí E-commerce Event Analytics** - Multi-event type analysis (purchases, searches, wishlists)\n",
        "2. **üè≠ IoT Sensor Processing** - Oil rig sensor data with diverse sensor types and readings\n",
        "3. **üõ°Ô∏è Security Log Analysis** - Multi-system security event correlation (Firewall, Antivirus, IDS)\n",
        "\n",
        "### üîß **Key Features**\n",
        "- **Unified Data Processing**: Handle diverse JSON structures with a single data type\n",
        "- **Performance Optimized**: CTE-based queries for distributed processing\n",
        "- **Real-World Patterns**: Industry-validated analysis techniques\n",
        "- **Mixed API Approach**: DataFrame API + SQL for optimal performance\n",
        "\n",
        "### üìä **Technical Highlights**\n",
        "- **Variant Data Type**: Native JSON processing without schema constraints\n",
        "- **VARIANT_GET()**: Type-safe data extraction from nested JSON\n",
        "- **parse_json()**: DataFrame API JSON parsing\n",
        "- **Cross-System Correlation**: Multi-source data analysis\n",
        "\n",
        "---\n",
        "\n",
        "**Authors**: Jules S. Damji & Cursor AI  \n",
        "**Requirements**: Apache Spark 4.0+ with Variant support  \n",
        "**Dataset Size**: Configurable (default: 60K records per use case)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import utility functions and required libraries\n",
        "import time\n",
        "from pyspark.sql.functions import col, parse_json\n",
        "\n",
        "# Import all data generation utilities\n",
        "from data_utility import (\n",
        "    generate_ecommerce_data,\n",
        "    generate_oil_rig_data, \n",
        "    generate_security_data\n",
        ")\n",
        "\n",
        "# Import individual use case runners\n",
        "from ecommerce_event_analytics import run_ecommerce_analysis\n",
        "from iot_sensor_processing import run_iot_analysis  \n",
        "from security_log_analysis import run_security_analysis\n",
        "\n",
        "print(\"‚úÖ All utility functions imported successfully\")\n",
        "print(f\"Spark Version: {spark.version}\")\n",
        "print(f\"Available Spark session: {spark}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üõí Use Case 1: E-commerce Event Analytics\n",
        "\n",
        "Analyze heterogeneous e-commerce events (purchases, searches, wishlists) using Variant data type for unified processing.\n",
        "\n",
        "### Key Analysis Areas:\n",
        "- Event type distribution and patterns\n",
        "- Purchase analysis by category and revenue\n",
        "- Search behavior and user preferences\n",
        "- User engagement across event types\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run E-commerce Analysis\n",
        "# Adjust num_records as needed (default: 60000 for full analysis, 10000 for quick demo)\n",
        "run_ecommerce_analysis(num_records=10000)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üè≠ Use Case 2: IoT Sensor Processing\n",
        "\n",
        "Process diverse IoT sensor data from oil rig operations with different sensor types and measurement structures.\n",
        "\n",
        "### Key Analysis Areas:\n",
        "- Sensor type distribution and health monitoring\n",
        "- Critical alerts and anomaly detection\n",
        "- Location-based analysis and trends\n",
        "- Equipment monitoring and maintenance insights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run IoT Sensor Analysis\n",
        "# Adjust num_records as needed (default: 60000 for full analysis, 10000 for quick demo)\n",
        "run_iot_analysis(num_records=10000)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üõ°Ô∏è Use Case 3: Security Log Analysis\n",
        "\n",
        "Analyze heterogeneous security logs from multiple systems (Firewall, Antivirus, IDS) for comprehensive threat detection.\n",
        "\n",
        "### Key Analysis Areas:\n",
        "- Multi-system security event correlation\n",
        "- Geographic threat intelligence\n",
        "- Severity-based threat prioritization\n",
        "- Cross-system IP correlation for advanced threat detection\n",
        "\n",
        "**Note**: All security analysis patterns have been validated against real-world SIEM practices.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run Security Log Analysis\n",
        "# Adjust num_records as needed (default: 60000 for full analysis, 10000 for quick demo)\n",
        "run_security_analysis(num_records=10000)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Interactive Use Case Runner\n",
        "\n",
        "Run specific use cases with custom parameters or run all use cases for a comprehensive demo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Interactive runner - uncomment and customize as needed\n",
        "\n",
        "# Option 1: Run specific use case with custom parameters\n",
        "# run_ecommerce_analysis(num_records=25000)\n",
        "# run_iot_analysis(num_records=15000)\n",
        "# run_security_analysis(num_records=30000)\n",
        "\n",
        "# Option 2: Quick demo of all use cases\n",
        "print(\"üöÄ Running quick demo of all use cases...\")\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"QUICK DEMO: ALL SPARK VARIANT USE CASES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Run all with smaller datasets for quick demonstration\n",
        "run_ecommerce_analysis(5000)\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "run_iot_analysis(5000)\n",
        "print(\"\\n\" + \"=\"*80) \n",
        "run_security_analysis(5000)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"‚úÖ ALL USE CASES COMPLETED SUCCESSFULLY!\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Available Utility Functions Reference\n",
        "\n",
        "### Data Generation Functions:\n",
        "\n",
        "```python\n",
        "# Main data generation functions (imported from data_utility)\n",
        "generate_ecommerce_data(num_records=1000)\n",
        "generate_oil_rig_data(num_records=1000) \n",
        "generate_security_data(num_records=1000)\n",
        "```\n",
        "\n",
        "### Analysis Functions:\n",
        "\n",
        "```python\n",
        "# Complete analysis runners (imported from respective modules)\n",
        "run_ecommerce_analysis(num_records=60000)\n",
        "run_iot_analysis(num_records=60000)\n",
        "run_security_analysis(num_records=60000)\n",
        "```\n",
        "\n",
        "### Key Spark Variant Functions:\n",
        "\n",
        "```sql\n",
        "-- Convert JSON string to Variant\n",
        "parse_json(column_name)\n",
        "\n",
        "-- Extract typed data from Variant\n",
        "VARIANT_GET(variant_column, '$.path', 'type')\n",
        "\n",
        "-- Supported types: 'string', 'int', 'double', 'boolean', 'array', 'object'\n",
        "```\n",
        "\n",
        "### File Structure:\n",
        "```\n",
        "variants/\n",
        "‚îú‚îÄ‚îÄ data_utility.py              # All data generation utilities\n",
        "‚îú‚îÄ‚îÄ ecommerce_event_analytics.py # E-commerce analysis\n",
        "‚îú‚îÄ‚îÄ iot_sensor_processing.py     # IoT sensor analysis  \n",
        "‚îú‚îÄ‚îÄ security_log_analysis.py     # Security log analysis\n",
        "‚îî‚îÄ‚îÄ spark_variant_analysis_notebook.ipynb # This notebook\n",
        "```\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
