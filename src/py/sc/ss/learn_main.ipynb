{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 🎓 Learn transformWithState on Databricks - The Simplest Way\n",
        "\n",
        "**Master Spark's transformWithState API in 15 minutes with development infrastructure!**\n",
        "\n",
        "This notebook demonstrates the core concepts of `transformWithState` using:\n",
        "- 🗄️ **RocksDB State Store** (multi-column family support)\n",
        "- 📁 **DBFS Checkpointing** (fault tolerance)\n",
        "- 🚀 **Auto-Scaling Clusters** (performance)\n",
        "- 💾 **Managed Infrastructure** (zero setup)\n",
        "\n",
        "## 🛫 Our Example: Flight State Tracking\n",
        "\n",
        "We track **3 flights** through **3 states**:\n",
        "- **Flights**: Delta1247, United892, Southwest5031\n",
        "- **States**: boarding → flying → landed → boarding (repeats)\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📚 Step 1: Understanding the Concepts\n",
        "\n",
        "Let's start by understanding what `transformWithState` does:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# First, let's understand the core concepts\n",
        "def explain_transform_with_state():\n",
        "    \"\"\"\n",
        "    Explain transformWithState concepts in simple terms.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"📚\" + \"=\"*60)\n",
        "    print(\"TRANSFORM WITH STATE ON DATABRICKS\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"\"\"\n",
        "🎯 THE BIG IDEA:\n",
        "   Keep information about each thing (like flights) between batches\n",
        "\n",
        "🔑 KEY CONCEPTS:\n",
        "\n",
        "1. GROUPING BY KEY\n",
        "   .groupBy(\"flight\")  ← Each flight gets separate processing\n",
        "\n",
        "2. STATE STORAGE  \n",
        "   Each flight remembers its current state (boarding/flying/landed)\n",
        "\n",
        "3. BATCH PROCESSING\n",
        "   Every few seconds, process new updates for each flight\n",
        "\n",
        "4. STATE PERSISTENCE\n",
        "   Flight state survives between batches - that's the magic!\n",
        "\n",
        "🛫 OUR EXAMPLE:\n",
        "   - Track flights: Delta1247, United892, Southwest5031\n",
        "   - States: boarding → flying → landed\n",
        "   - Each flight remembers where it is\n",
        "\n",
        "🧠 MENTAL MODEL:\n",
        "   Think of it like having a notebook for each flight.\n",
        "   Every batch, you:\n",
        "   1. Look up the flight's current page in the notebook\n",
        "   2. Read what state it was in\n",
        "   3. Update it based on new information  \n",
        "   4. Write the new state back to the notebook\n",
        "   5. The notebook persists for the next batch!\n",
        "\n",
        "🏗️ DATABRICKS ADVANTAGES:\n",
        "   - 🗄️  RocksDB state store (production-grade)\n",
        "   - 📁 DBFS checkpointing (fault tolerance)\n",
        "   - 🚀 Auto-scaling clusters (performance)\n",
        "   - 💾 Multi-column family support (advanced features)\n",
        "   - 🔧 Managed infrastructure (no setup headaches)\n",
        "\n",
        "⚙️ THE API:\n",
        "   - transformWithState gives you full control\n",
        "   - StatefulProcessor handles the state logic\n",
        "   - You decide what to store and how to update it\n",
        "   - Databricks makes it production-ready!\n",
        "\"\"\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"🚀 READY TO SEE IT ON DATABRICKS!\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "# Run the explanation\n",
        "explain_transform_with_state()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔧 Step 2: Create Databricks Spark Session\n",
        "\n",
        "Let's set up Spark with Databricks-optimized configurations:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import utility functions from our utils notebook\n",
        "%run ./databricks_utils\n",
        "\n",
        "# Create the Databricks-optimized Spark session\n",
        "spark = create_spark()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📊 Step 3: Create Flight Data Stream\n",
        "\n",
        "Let's create a simple data stream that generates flight state updates:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the flight data stream\n",
        "flight_data = create_flight_data(spark)\n",
        "\n",
        "# Let's see what the data looks like\n",
        "print(\"\\n📋 Flight Data Schema:\")\n",
        "flight_data.printSchema()\n",
        "\n",
        "print(\"\\n📊 Sample data explanation:\")\n",
        "print(\"   - 🛫 3 flights: Delta1247, United892, Southwest5031\")\n",
        "print(\"   - 🔄 3 states: boarding → flying → landed (cycling)\")\n",
        "print(\"   - ⏱️  1 row per second from rate source\")\n",
        "print(\"   - 🎯 Each flight gets separate state tracking\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🚀 Step 4: Run the transformWithState Demo\n",
        "\n",
        "Now let's see `transformWithState` in action on Databricks!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run the complete demo - this will start the streaming query\n",
        "print(\"🎓 Starting the transformWithState learning demo...\")\n",
        "print(\"📝 This will show you:\")\n",
        "print(\"   - 🗄️  How RocksDB manages state for each flight\")\n",
        "print(\"   - ✅ State transitions in real-time\")\n",
        "print(\"   - 📈 Update counts increasing over time\")\n",
        "print(\"   - 💾 State persistence across micro-batches\")\n",
        "print(\"   - 🚀 Production-grade streaming on Databricks\")\n",
        "print(\"\\n⚠️  Note: This will run until you stop it manually!\")\n",
        "print(\"   Use the next cell to stop the demo when ready.\")\n",
        "\n",
        "# Uncomment the line below to start the demo\n",
        "# run_learning_demo(spark)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🎉 Congratulations!\n",
        "\n",
        "You've successfully learned `transformWithState` on Databricks! Here's what you accomplished:\n",
        "\n",
        "### ✅ What You Learned:\n",
        "- 🗄️ **RocksDB State Management**: How Databricks handles state with multi-column family support\n",
        "- 📁 **DBFS Checkpointing**: Fault-tolerant streaming with distributed file system\n",
        "- ⚙️ **StatefulProcessor API**: Custom state logic with `init()`, `handleInputRows()`, etc.\n",
        "- 🔄 **State Transitions**: Validation and business logic in streaming context\n",
        "- 🚀 **Production Infrastructure**: Auto-scaling, managed clusters, zero setup\n",
        "\n",
        "### 🎯 Key Concepts Mastered:\n",
        "1. **Grouping by Key**: Each flight gets separate state management\n",
        "2. **State Persistence**: Information survives between micro-batches\n",
        "3. **Custom Processing**: Full control over state logic and transitions\n",
        "4. **Fault Tolerance**: Checkpointing ensures reliability\n",
        "5. **Production Ready**: Databricks infrastructure handles scaling\n",
        "\n",
        "### 🚀 Next Steps:\n",
        "- Try modifying the state transition rules\n",
        "- Add more complex business logic\n",
        "- Experiment with timers and TTL\n",
        "- Scale up with more flights and states\n",
        "- Integrate with Delta Lake for persistence\n",
        "\n",
        "---\n",
        "\n",
        "**🎓 You've mastered transformWithState on Databricks in 15 minutes!**\n",
        "\n",
        "*Flight Numbers*: Delta1247, United892, Southwest5031  \n",
        "*States*: boarding → flying → landed  \n",
        "*Infrastructure*: RocksDB, DBFS, Auto-scaling  \n",
        "*Code Quality*: Type hints, docstrings, production standards\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
