{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ“ Learn transformWithState on Databricks - The Simplest Way\n",
        "\n",
        "**Master Spark's transformWithState API in 15 minutes with development infrastructure!**\n",
        "\n",
        "This notebook demonstrates the core concepts of `transformWithState` using:\n",
        "- ğŸ—„ï¸ **RocksDB State Store** (multi-column family support)\n",
        "- ğŸ“ **DBFS Checkpointing** (fault tolerance)\n",
        "- ğŸš€ **Auto-Scaling Clusters** (performance)\n",
        "- ğŸ’¾ **Managed Infrastructure** (zero setup)\n",
        "\n",
        "## ğŸ›« Our Example: Flight State Tracking\n",
        "\n",
        "We track **3 flights** through **3 states**:\n",
        "- **Flights**: Delta1247, United892, Southwest5031\n",
        "- **States**: boarding â†’ flying â†’ landed â†’ boarding (repeats)\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“š Step 1: Understanding the Concepts\n",
        "\n",
        "Let's start by understanding what `transformWithState` does:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# First, let's understand the core concepts\n",
        "def explain_transform_with_state():\n",
        "    \"\"\"\n",
        "    Explain transformWithState concepts in simple terms.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"ğŸ“š\" + \"=\"*60)\n",
        "    print(\"TRANSFORM WITH STATE ON DATABRICKS\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"\"\"\n",
        "ğŸ¯ THE BIG IDEA:\n",
        "   Keep information about each thing (like flights) between batches\n",
        "\n",
        "ğŸ”‘ KEY CONCEPTS:\n",
        "\n",
        "1. GROUPING BY KEY\n",
        "   .groupBy(\"flight\")  â† Each flight gets separate processing\n",
        "\n",
        "2. STATE STORAGE  \n",
        "   Each flight remembers its current state (boarding/flying/landed)\n",
        "\n",
        "3. BATCH PROCESSING\n",
        "   Every few seconds, process new updates for each flight\n",
        "\n",
        "4. STATE PERSISTENCE\n",
        "   Flight state survives between batches - that's the magic!\n",
        "\n",
        "ğŸ›« OUR EXAMPLE:\n",
        "   - Track flights: Delta1247, United892, Southwest5031\n",
        "   - States: boarding â†’ flying â†’ landed\n",
        "   - Each flight remembers where it is\n",
        "\n",
        "ğŸ§  MENTAL MODEL:\n",
        "   Think of it like having a notebook for each flight.\n",
        "   Every batch, you:\n",
        "   1. Look up the flight's current page in the notebook\n",
        "   2. Read what state it was in\n",
        "   3. Update it based on new information  \n",
        "   4. Write the new state back to the notebook\n",
        "   5. The notebook persists for the next batch!\n",
        "\n",
        "ğŸ—ï¸ DATABRICKS ADVANTAGES:\n",
        "   - ğŸ—„ï¸  RocksDB state store (production-grade)\n",
        "   - ğŸ“ DBFS checkpointing (fault tolerance)\n",
        "   - ğŸš€ Auto-scaling clusters (performance)\n",
        "   - ğŸ’¾ Multi-column family support (advanced features)\n",
        "   - ğŸ”§ Managed infrastructure (no setup headaches)\n",
        "\n",
        "âš™ï¸ THE API:\n",
        "   - transformWithState gives you full control\n",
        "   - StatefulProcessor handles the state logic\n",
        "   - You decide what to store and how to update it\n",
        "   - Databricks makes it production-ready!\n",
        "\"\"\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"ğŸš€ READY TO SEE IT ON DATABRICKS!\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "# Run the explanation\n",
        "explain_transform_with_state()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ”§ Step 2: Create Databricks Spark Session\n",
        "\n",
        "Let's set up Spark with Databricks-optimized configurations:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import utility functions from our utils notebook\n",
        "%run ./databricks_utils\n",
        "\n",
        "# Create the Databricks-optimized Spark session\n",
        "spark = create_spark()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“Š Step 3: Create Flight Data Stream\n",
        "\n",
        "Let's create a simple data stream that generates flight state updates:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the flight data stream\n",
        "flight_data = create_flight_data(spark)\n",
        "\n",
        "# Let's see what the data looks like\n",
        "print(\"\\nğŸ“‹ Flight Data Schema:\")\n",
        "flight_data.printSchema()\n",
        "\n",
        "print(\"\\nğŸ“Š Sample data explanation:\")\n",
        "print(\"   - ğŸ›« 3 flights: Delta1247, United892, Southwest5031\")\n",
        "print(\"   - ğŸ”„ 3 states: boarding â†’ flying â†’ landed (cycling)\")\n",
        "print(\"   - â±ï¸  1 row per second from rate source\")\n",
        "print(\"   - ğŸ¯ Each flight gets separate state tracking\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸš€ Step 4: Run the transformWithState Demo\n",
        "\n",
        "Now let's see `transformWithState` in action on Databricks!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run the complete demo - this will start the streaming query\n",
        "print(\"ğŸ“ Starting the transformWithState learning demo...\")\n",
        "print(\"ğŸ“ This will show you:\")\n",
        "print(\"   - ğŸ—„ï¸  How RocksDB manages state for each flight\")\n",
        "print(\"   - âœ… State transitions in real-time\")\n",
        "print(\"   - ğŸ“ˆ Update counts increasing over time\")\n",
        "print(\"   - ğŸ’¾ State persistence across micro-batches\")\n",
        "print(\"   - ğŸš€ Production-grade streaming on Databricks\")\n",
        "print(\"\\nâš ï¸  Note: This will run until you stop it manually!\")\n",
        "print(\"   Use the next cell to stop the demo when ready.\")\n",
        "\n",
        "# Uncomment the line below to start the demo\n",
        "# run_learning_demo(spark)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ‰ Congratulations!\n",
        "\n",
        "You've successfully learned `transformWithState` on Databricks! Here's what you accomplished:\n",
        "\n",
        "### âœ… What You Learned:\n",
        "- ğŸ—„ï¸ **RocksDB State Management**: How Databricks handles state with multi-column family support\n",
        "- ğŸ“ **DBFS Checkpointing**: Fault-tolerant streaming with distributed file system\n",
        "- âš™ï¸ **StatefulProcessor API**: Custom state logic with `init()`, `handleInputRows()`, etc.\n",
        "- ğŸ”„ **State Transitions**: Validation and business logic in streaming context\n",
        "- ğŸš€ **Production Infrastructure**: Auto-scaling, managed clusters, zero setup\n",
        "\n",
        "### ğŸ¯ Key Concepts Mastered:\n",
        "1. **Grouping by Key**: Each flight gets separate state management\n",
        "2. **State Persistence**: Information survives between micro-batches\n",
        "3. **Custom Processing**: Full control over state logic and transitions\n",
        "4. **Fault Tolerance**: Checkpointing ensures reliability\n",
        "5. **Production Ready**: Databricks infrastructure handles scaling\n",
        "\n",
        "### ğŸš€ Next Steps:\n",
        "- Try modifying the state transition rules\n",
        "- Add more complex business logic\n",
        "- Experiment with timers and TTL\n",
        "- Scale up with more flights and states\n",
        "- Integrate with Delta Lake for persistence\n",
        "\n",
        "---\n",
        "\n",
        "**ğŸ“ You've mastered transformWithState on Databricks in 15 minutes!**\n",
        "\n",
        "*Flight Numbers*: Delta1247, United892, Southwest5031  \n",
        "*States*: boarding â†’ flying â†’ landed  \n",
        "*Infrastructure*: RocksDB, DBFS, Auto-scaling  \n",
        "*Code Quality*: Type hints, docstrings, production standards\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
